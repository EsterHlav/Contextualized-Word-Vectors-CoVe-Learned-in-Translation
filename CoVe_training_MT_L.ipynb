{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container {\n",
       "        width: 100%;\n",
       "        padding: 0px !important;\n",
       "    }\n",
       "\n",
       "@media (max-width:1200px) {\n",
       "    #notebook[tabindex=\"-1\"] {\n",
       "        padding-top: 0px !important;\n",
       "    }\n",
       "    .prompt {\n",
       "        min-width: 8ex;\n",
       "    }\n",
       "    .input_prompt {\n",
       "        font-weight: bold;\n",
       "        position: absolute;\n",
       "        padding-right: 0px;\n",
       "        padding-top: 2px;\n",
       "        padding-bottom: 0px;\n",
       "        padding-left: 8px;\n",
       "        font-size: 10px !important;\n",
       "    }\n",
       "    .CodeMirror-lines {\n",
       "        padding-top:12px !important;\n",
       "    }\n",
       "    pre {\n",
       "        white-space: pre-wrap !important;\n",
       "    }\n",
       "}    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".container {\n",
    "        width: 100%;\n",
    "        padding: 0px !important;\n",
    "    }\n",
    "\n",
    "@media (max-width:1200px) {\n",
    "    #notebook[tabindex=\"-1\"] {\n",
    "        padding-top: 0px !important;\n",
    "    }\n",
    "    .prompt {\n",
    "        min-width: 8ex;\n",
    "    }\n",
    "    .input_prompt {\n",
    "        font-weight: bold;\n",
    "        position: absolute;\n",
    "        padding-right: 0px;\n",
    "        padding-top: 2px;\n",
    "        padding-bottom: 0px;\n",
    "        padding-left: 8px;\n",
    "        font-size: 10px !important;\n",
    "    }\n",
    "    .CodeMirror-lines {\n",
    "        padding-top:12px !important;\n",
    "    }\n",
    "    pre {\n",
    "        white-space: pre-wrap !important;\n",
    "    }\n",
    "}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and set params experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os, re, sys\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from itertools import compress\n",
    "import pickle\n",
    "from preprocessing import *\n",
    "import glob\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/wmt17/de-en/europarl-v7.de-en.clean.de.tok', 'data/wmt17/de-en/commoncrawl.de-en.clean.en.tok', 'data/wmt17/de-en/newstest2013.de.tok', 'data/wmt17/de-en/news-commentary-v12.de-en.clean.en.tok', 'data/wmt17/de-en/rapid2016.de-en.clean.en.tok', 'data/wmt17/de-en/rapid2016.de-en.clean.de.tok', 'data/wmt17/de-en/commoncrawl.de-en.clean.de.tok', 'data/wmt17/de-en/newstest2013.en.tok', 'data/wmt17/de-en/news-commentary-v12.de-en.clean.de.tok', 'data/wmt17/de-en/europarl-v7.de-en.clean.en.tok']\n",
      "['data/wmt17/de-en/rapid2016.de-en.clean.de.tok.low', 'data/wmt17/de-en/europarl-v7.de-en.clean.de.tok.low', 'data/wmt17/de-en/newstest2013.de.tok.low', 'data/wmt17/de-en/newstest2013.en.tok.low', 'data/wmt17/de-en/rapid2016.de-en.clean.en.tok.low', 'data/wmt17/de-en/europarl-v7.de-en.clean.en.tok.low', 'data/wmt17/de-en/train.clean.de.tok.low', 'data/wmt17/de-en/commoncrawl.de-en.clean.en.tok.low', 'data/wmt17/de-en/news-commentary-v12.de-en.clean.de.tok.low', 'data/wmt17/de-en/news-commentary-v12.de-en.clean.en.tok.low', 'data/wmt17/de-en/commoncrawl.de-en.clean.de.tok.low', 'data/wmt17/de-en/train.clean.en.tok.low']\n"
     ]
    }
   ],
   "source": [
    "path= 'data/wmt17/de-en/'\n",
    "print (list(glob.iglob(os.path.join(path, '*.tok'))))\n",
    "print (list(glob.iglob(os.path.join(path, '*.low'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run preprocessing WMT17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####    Processing the files    #####\n",
      "Start loading training data.\n",
      "Starting on src\n",
      "Starting on tgt\n",
      "dict_keys(['src', 'tgt'])\n",
      "Done loading training data.\n",
      "\n",
      "Start filter length training data sentences.\n",
      "Loop filter max seq length...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6ef1c5c31d4727ad672a28dbb424d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filtering train set: max length 'src' = 50  /  max length 'tgt' = 50\n",
      "Done filter length training data sentences.\n",
      "\n",
      "Create vocab src from training.\n",
      "Done creating vocab src from training.\n",
      "\n",
      "Create vocab tgt from training.\n",
      "Done creating vocab tgt from training.\n",
      "\n",
      "Tokenize src...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dc8283fd4548ea888d8214c5774d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenize tgt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a814d0967364c9786a62782219bfef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loop filter max seq length...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cac3252eca14323888a22afc02bb4ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filtering val set: max length 'src' = 50  /  max length 'tgt' = 50\n",
      "Tokenize src...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3018199f4244eda3590a0f5ec33f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenize tgt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fba73d7f5d47cd9ecdbc13ca454507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading GloVe from txt file...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1440818c176a47e38105aae9d70f77ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating all embeddings for src\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40c2605010f4273afb39e9bd6d54e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading Charemb kazuma from txt file...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6a52a9069844a6b5f23cb7513e57f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modify all embeddings for src with charemb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac2719c055043dc8cd26ee426d0a5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done with vocabulary.\n",
      "#####     Saving the dataset     #####\n",
      "Saving the dataset...\n",
      "Done saving the data\n",
      "Saved at data/saved_preprocess/wmt17_30000_50_glove_charemb.p\n"
     ]
    }
   ],
   "source": [
    "# News Commentary\n",
    "#-train_src data/wmt17/de-en/news-commentary-v12.de-en.clean.en.tok.low -train_tgt data/wmt17/de-en/news-commentary-v12.de-en.clean.de.tok.low -valid_src data/wmt17/de-en/newstest2013.en.tok.low -valid_tgt data/wmt17/de-en/newstest2013.de.tok.low -save_data data/news-commentary.clean.tok.low -lower -seq_length 75\n",
    "\n",
    "# Rapid Fire\n",
    "#-train_src data/wmt17/de-en/rapid*.clean.en.tok.low -train_tgt data/wmt17/de-en/rapid*.clean.de.tok.low -valid_src data/wmt17/de-en/newstest2013.en.tok.low -valid_tgt data/wmt17/de-en/newstest2013.de.tok.low -save_data data/rapid.clean.tok.low -lower -seq_length 75\n",
    "\n",
    "# Europarl\n",
    "#-train_src data/wmt17/de-en/europarl*.clean.en.tok.low -train_tgt data/wmt17/de-en/europarl*.clean.de.tok.low -valid_src data/wmt17/de-en/newstest2013.en.tok.low -valid_tgt data/wmt17/de-en/newstest2013.de.tok.low -save_data data/europarl.clean.tok.low -lower -seq_length 75\n",
    "\n",
    "# Common Crawl\n",
    "#-train_src data/wmt17/de-en/commoncrawl*.clean.en.tok.low -train_tgt data/wmt17/de-en/commoncrawl*.clean.de.tok.low -valid_src data/wmt17/de-en/newstest2013.en.tok.low -valid_tgt data/wmt17/de-en/newstest2013.de.tok.low -save_data data/commoncrawl.clean.tok.low -lower -seq_length 75\n",
    "\n",
    "# WMT'17\n",
    "#-train_src data/wmt17/de-en/train.clean.en.tok.low -train_tgt data/wmt17/de-en/train.clean.de.tok.low -valid_src data/wmt17/de-en/newstest2013.en.tok.low -valid_tgt data/wmt17/de-en/newstest2013.de.tok.low -save_data data/wmt17.clean.tok.low -lower -seq_length 75\n",
    "\n",
    "\n",
    "# path IWSLT17\n",
    "p = os.path.join('data','wmt17', 'de-en')\n",
    "\n",
    "# dict of paths\n",
    "dict_srcl_tgtl_path_wmt17 = {\n",
    "                       'train': {\n",
    "                           'src': os.path.join(p, 'train.clean.en.tok.low'), 'tgt': os.path.join(p, 'train.clean.de.tok.low')\n",
    "                           },\n",
    "                        'val': {\n",
    "                           'src': os.path.join(p, 'newstest2013.en.tok.low'), 'tgt': os.path.join(p, 'newstest2013.de.tok.low')\n",
    "                           }\n",
    "                      }\n",
    "\n",
    "# -> for preprocessing\n",
    "path_save = 'data/saved_preprocess/wmt17'\n",
    "# -> to load preprocessing\n",
    "# path_save = 'data/saved_preprocess/wmt17_30000_50_glove_charemb.p'\n",
    "\n",
    "if path_save.split('.')[-1] != 'p':\n",
    "    # preprocess data...\n",
    "    Preprocess_wmt17 = PreprocessorMT(dict_srcl_tgtl_path_wmt17,\\\n",
    "                     path_save=path_save,\\\n",
    "                     max_vocab_src=30000, max_vocab_tgt=30000, max_seq_length=50,\\\n",
    "                     glove_path='data/GloVe/glove.840B.300d.txt', charemb_path='data/kazuma/charNgram.txt', test=False)\n",
    "\n",
    "    Preprocess_wmt17.process_and_save()\n",
    "else:\n",
    "    # or load preprocessed file\n",
    "    print ('Loading the preprocessed data...')\n",
    "    Preprocess_wmt17 = pickle.load(open(path_save, 'rb'))\n",
    "    print ('Done loading the preprocessed data!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of set train: 485925\n",
      "Size of set val: 345\n"
     ]
    }
   ],
   "source": [
    "for mode in ['train', 'val']:\n",
    "    print (\"Size of set {}: {}\".format(mode, Preprocess_wmt17.get_length_set(mode)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NMT import *\n",
    "dataset_MT = dataset(Preprocess_wmt17)\n",
    "\n",
    "default_params = {\n",
    "    'dataset': None,\n",
    "    'save_path': '',\n",
    "    'mode': 'TRAIN',\n",
    "    'nb_layers_enc': None,\n",
    "    'nb_layers_dec': None,\n",
    "    'embedding_dim': 300,\n",
    "    'train_emb_src': True,\n",
    "    'init_emb': None,\n",
    "    'lstm_size_enc': 600,\n",
    "    'lstm_size_dec': 600,\n",
    "    'nb_layers_enc': 2,\n",
    "    'nb_layers_dec': 2,\n",
    "    'keep_probability': 0.8,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 20,\n",
    "    'EOS': \"</s>\",\n",
    "    'SOS': \"<s>\",\n",
    "    'PAD': '<pad>',\n",
    "    'clip': 5,\n",
    "    'lr': 0.001,\n",
    "    'lr_decay': 0.9,\n",
    "    'lr_decay_steps': 100,\n",
    "    'print_update': 25,\n",
    "    'patience': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training of seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph of model is built.\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "src_embedding:0 (float32_ref 30000x400) [12000000, bytes: 48000000]\n",
      "tgt_embedding:0 (float32_ref 30000x400) [12000000, bytes: 48000000]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/kernel:0 (float32_ref 700x1200) [840000, bytes: 3360000]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/bias:0 (float32_ref 1200) [1200, bytes: 4800]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/kernel:0 (float32_ref 700x1200) [840000, bytes: 3360000]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/bias:0 (float32_ref 1200) [1200, bytes: 4800]\n",
      "dynamic_seq2seq/decoder/memory_layer/kernel:0 (float32_ref 600x600) [360000, bytes: 1440000]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/kernel:0 (float32_ref 1600x2400) [3840000, bytes: 15360000]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/bias:0 (float32_ref 2400) [2400, bytes: 9600]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/kernel:0 (float32_ref 1200x2400) [2880000, bytes: 11520000]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/bias:0 (float32_ref 2400) [2400, bytes: 9600]\n",
      "dynamic_seq2seq/decoder/output_projection/kernel:0 (float32_ref 600x30000) [18000000, bytes: 72000000]\n",
      "dynamic_seq2seq/decoder/output_projection/bias:0 (float32_ref 30000) [30000, bytes: 120000]\n",
      "Total size of variables: 50797200\n",
      "Total bytes of variables: 203188800\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "train_params = default_params\n",
    "train_params['dataset'] = dataset_MT\n",
    "train_params['lstm_size_enc'] = 600\n",
    "train_params['lstm_size_dec'] = 600\n",
    "train_params['nb_layers_enc'] = 2\n",
    "train_params['nb_layers_dec'] = 2\n",
    "train_params['embedding_dim'] = 400 # because GLoVe+charemb\n",
    "train_params['init_emb'] = np.vstack(list(map(lambda i: dataset_MT.data.vocab_src.embeddings[dataset_MT.data.vocab_src.idx2lab[i]], np.arange(dataset_MT.data.vocab_src.size)))).astype(np.float32)\n",
    "train_params['batch_size'] = 256\n",
    "train_params['epochs'] = 1\n",
    "train_params['mode'] = 'TRAIN' \n",
    "train_params['save_path'] = 'save_run/MT_L/run1'\n",
    "\n",
    "nmt  =  NMT(train_params)\n",
    "  \n",
    "nmt.build_model()\n",
    "\n",
    "model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Epoch 0 of 1 --------------------\n",
      "Iteration: 0 of 1897\ttrain_loss: 10.3093\n",
      "Overall BLEU-4 on 256 sentences: 0.0000\n",
      "----------------------------------------\n",
      "Example n°1:\n",
      "\n",
      "Src sentence:  to remedy this is very expensive <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Tgt sentence:  <s> dagegen <unk> kostet viel </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Tgt predicted: <s> <s> <s> </s> </s> </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Bleu score:    0\n",
      "----------------------------------------\n",
      "Example n°2:\n",
      "\n",
      "Src sentence:  should the judiciary be deprived of power ? <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Tgt sentence:  <s> soll die judikative <unk> werden ? </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Tgt predicted: <s> <s> <s> </s> </s> </s> </s> </s> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Bleu score:    0\n",
      "Iteration: 25 of 1897\ttrain_loss: 5.6864\n",
      "Iteration: 50 of 1897\ttrain_loss: 5.3092\n",
      "Iteration: 75 of 1897\ttrain_loss: 5.0452\n",
      "Iteration: 100 of 1897\ttrain_loss: 4.8979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall BLEU-4 on 256 sentences: 0.0000\n",
      "----------------------------------------\n",
      "Example n°1:\n",
      "\n",
      "Src sentence:  donations for the new soul <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Tgt sentence:  <s> spenden für die neue seele </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Tgt predicted: <s> <s> <unk> <unk> </s> </s> </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Bleu score:    0\n",
      "----------------------------------------\n",
      "Example n°2:\n",
      "\n",
      "Src sentence:  and , in a match , it 's easier . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Tgt sentence:  <s> und bei einem spiel ist dies noch einfacher . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Tgt predicted: <s> <s> <unk> <unk> <unk> <unk> . . . . </s> <pad> <pad> <pad>\n",
      "Bleu score:    0.0\n",
      "Iteration: 125 of 1897\ttrain_loss: 4.7816\n",
      "Iteration: 150 of 1897\ttrain_loss: 4.7094\n",
      "Iteration: 175 of 1897\ttrain_loss: 4.5680\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-49e5ef701bc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_nb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_bleu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/CoVe.CoVe.eh2757/NMT.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset_MT, restore_path, save, print_nb, print_bleu)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# shuffle the input data before every epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mdataset_MT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_MT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_nb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_nb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_bleu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_bleu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/CoVe.CoVe.eh2757/NMT.py\u001b[0m in \u001b[0;36moptimize_epoch\u001b[0;34m(self, dataset_MT, epoch, print_nb, print_bleu)\u001b[0m\n\u001b[1;32m    492\u001b[0m             }\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;31m# print loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nmt.train(save=True, print_nb=2, print_bleu=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference on training set (2048 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph of model is built.\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "src_embedding:0 (float32_ref 30000x400) [12000000, bytes: 48000000]\n",
      "tgt_embedding:0 (float32_ref 30000x400) [12000000, bytes: 48000000]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/kernel:0 (float32_ref 700x1200) [840000, bytes: 3360000]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/bias:0 (float32_ref 1200) [1200, bytes: 4800]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/kernel:0 (float32_ref 700x1200) [840000, bytes: 3360000]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/bias:0 (float32_ref 1200) [1200, bytes: 4800]\n",
      "dynamic_seq2seq/decoder/memory_layer/kernel:0 (float32_ref 600x600) [360000, bytes: 1440000]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/kernel:0 (float32_ref 1600x2400) [3840000, bytes: 15360000]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/bias:0 (float32_ref 2400) [2400, bytes: 9600]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/kernel:0 (float32_ref 1200x2400) [2880000, bytes: 11520000]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/bias:0 (float32_ref 2400) [2400, bytes: 9600]\n",
      "dynamic_seq2seq/decoder/output_projection/kernel:0 (float32_ref 600x30000) [18000000, bytes: 72000000]\n",
      "dynamic_seq2seq/decoder/output_projection/bias:0 (float32_ref 30000) [30000, bytes: 120000]\n",
      "Total size of variables: 50797200\n",
      "Total bytes of variables: 203188800\n",
      "Restore graph from save_run/MT_L/run1\n",
      "INFO:tensorflow:Restoring parameters from save_run/MT_L/run1\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for save_run/MT_L/run1\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-554528956969>\", line 23, in <module>\n    preds = nmt_infer.infer(dataset_MT.data.data_tok['train'], idx, restore_path = infer_params['save_path'])\n  File \"/Users/i692122/Downloads/CoVe.CoVe.eh2757/NMT.py\", line 518, in infer\n    self.initialize_session()\n  File \"/Users/i692122/Downloads/CoVe.CoVe.eh2757/NMT.py\", line 564, in initialize_session\n    self.saver = tf.train.Saver()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1338, in __init__\n    self.build()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 835, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 472, in _AddRestoreOps\n    restore_sequentially)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 886, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for save_run/MT_L/run1\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for save_run/MT_L/run1\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-554528956969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_MT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_length_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmt_infer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_MT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_tok\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'save_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/CoVe.CoVe.eh2757/NMT.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, inputs, idxs, restore_path)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \"\"\"\n\u001b[1;32m    518\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;31m# create input data for NN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/CoVe.CoVe.eh2757/NMT.py\u001b[0m in \u001b[0;36mrestore_session\u001b[0;34m(self, restore_path)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \"\"\"\n\u001b[1;32m    571\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Restore graph from {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Graph restored!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1800\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1802\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for save_run/MT_L/run1\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-554528956969>\", line 23, in <module>\n    preds = nmt_infer.infer(dataset_MT.data.data_tok['train'], idx, restore_path = infer_params['save_path'])\n  File \"/Users/i692122/Downloads/CoVe.CoVe.eh2757/NMT.py\", line 518, in infer\n    self.initialize_session()\n  File \"/Users/i692122/Downloads/CoVe.CoVe.eh2757/NMT.py\", line 564, in initialize_session\n    self.saver = tf.train.Saver()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1338, in __init__\n    self.build()\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 835, in _build_internal\n    restore_sequentially, reshape)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 472, in _AddRestoreOps\n    restore_sequentially)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 886, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1463, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/Users/i692122/anaconda3/envs/tf_1_8/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for save_run/MT_L/run1\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "infer_params = default_params\n",
    "infer_params['dataset'] = dataset_MT\n",
    "infer_params['lstm_size_enc'] = 600\n",
    "infer_params['lstm_size_dec'] = 600\n",
    "infer_params['nb_layers_enc'] = 2\n",
    "infer_params['nb_layers_dec'] = 2\n",
    "infer_params['embedding_dim'] = 400 # because GLoVe+charemb\n",
    "infer_params['init_emb'] = np.vstack(list(map(lambda i: dataset_MT.data.vocab_src.embeddings[dataset_MT.data.vocab_src.idx2lab[i]],\\\n",
    "                                              np.arange(dataset_MT.data.vocab_src.size)))).astype(np.float32)\n",
    "infer_params['batch_size'] = 2048\n",
    "infer_params['mode'] = 'INFER' \n",
    "infer_params['save_path'] = 'save_run/MT_L/run1'\n",
    "\n",
    "nmt_infer  =  NMT(infer_params)\n",
    "  \n",
    "nmt_infer.build_model()\n",
    "\n",
    "model_summary()\n",
    "\n",
    "idx = np.random.choice(dataset_MT.data.get_length_set('train'), 2048)\n",
    "preds = nmt_infer.infer(dataset_MT.data.data_tok['train'], idx, restore_path = infer_params['save_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall BLEU-4 on 2048 sentences: 0.0184\n",
      "------------------------------------------------------------\n",
      "Example n°1:\n",
      "\n",
      "Src sentence:  four boys run away up an incline .\n",
      "Tgt sentence:  vier jungen rennen einen hang hinauf davon .\n",
      "Tgt predicted: <s> ein ein in einem einem . . </s> </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°2:\n",
      "\n",
      "Src sentence:  four women interact at a conference .\n",
      "Tgt sentence:  vier frauen interagieren auf einer konferenz .\n",
      "Tgt predicted: <s> ein mann in einem . . </s> </s> </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°3:\n",
      "\n",
      "Src sentence:  a woman in a dress doing a craft .\n",
      "Tgt sentence:  eine frau in einem kleid bastelt etwas .\n",
      "Tgt predicted: <s> ein ein mann in einem einem . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°4:\n",
      "\n",
      "Src sentence:  men are sitting on bags on the ground .\n",
      "Tgt sentence:  männer sitzen auf ihren taschen auf dem boden .\n",
      "Tgt predicted: <s> ein ein in auf einem . . </s> </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°5:\n",
      "\n",
      "Src sentence:  an asian boy is leaning against a pole .\n",
      "Tgt sentence:  ein asiatischer junge lehnt gegen einen pfosten .\n",
      "Tgt predicted: <s> ein ein mann in einem . . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°6:\n",
      "\n",
      "Src sentence:  children playing leapfrog beside fountain .\n",
      "Tgt sentence:  kinder spielen neben einer fontäne bockspringen .\n",
      "Tgt predicted: <s> ein mann in . . </s> </s> </s> </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°7:\n",
      "\n",
      "Src sentence:  a group of cats sit in the grass .\n",
      "Tgt sentence:  viele katzen sitzen im gras .\n",
      "Tgt predicted: <s> ein ein in auf einem . . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°8:\n",
      "\n",
      "Src sentence:  a small baby dress in yellow smiles .\n",
      "Tgt sentence:  ein kleines baby in einem gelben kleid lächelt .\n",
      "Tgt predicted: <s> ein ein mann auf einem . . </s> </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°9:\n",
      "\n",
      "Src sentence:  a lady being arrested by a lady cop .\n",
      "Tgt sentence:  eine frau wird von einer polizistin verhaftet .\n",
      "Tgt predicted: <s> ein ein mann auf einem . . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°10:\n",
      "\n",
      "Src sentence:  man with gray shirt with a white name badge .\n",
      "Tgt sentence:  mann mit grauem hemd und weißem namensschild .\n",
      "Tgt predicted: <s> ein ein mann in einem einem . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°11:\n",
      "\n",
      "Src sentence:  man playing a brown and white electric guitar .\n",
      "Tgt sentence:  ein mann spielt eine braune und weiße e-gitarre .\n",
      "Tgt predicted: <s> ein ein mann auf einem . . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°12:\n",
      "\n",
      "Src sentence:  a white cat sits on a wall .\n",
      "Tgt sentence:  eine weiße katze sitzt auf einer mauer .\n",
      "Tgt predicted: <s> ein ein mann auf einem . . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°13:\n",
      "\n",
      "Src sentence:  a girl is laughing while sitting on a couch .\n",
      "Tgt sentence:  ein mädchen sitzt lachend auf einem sofa .\n",
      "Tgt predicted: <s> ein ein mann in einem einem . . . </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°14:\n",
      "\n",
      "Src sentence:  a woman on a bike racing .\n",
      "Tgt sentence:  eine frau fährt ein radrennen .\n",
      "Tgt predicted: <s> ein ein in einem einem . . </s> </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°15:\n",
      "\n",
      "Src sentence:  two boys cutting some meat .\n",
      "Tgt sentence:  zwei jungen schneiden fleisch .\n",
      "Tgt predicted: <s> ein mann in einem . . </s> </s> </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "BLEU_set(dataset_MT, idx, preds, 'train', samples=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph of model is built.\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "src_embedding:0 (float32_ref 3023x400) [1209200, bytes: 4836800]\n",
      "tgt_embedding:0 (float32_ref 3819x400) [1527600, bytes: 6110400]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/kernel:0 (float32_ref 700x1200) [840000, bytes: 3360000]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/bias:0 (float32_ref 1200) [1200, bytes: 4800]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/kernel:0 (float32_ref 700x1200) [840000, bytes: 3360000]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/bias:0 (float32_ref 1200) [1200, bytes: 4800]\n",
      "dynamic_seq2seq/decoder/memory_layer/kernel:0 (float32_ref 600x600) [360000, bytes: 1440000]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/kernel:0 (float32_ref 1600x2400) [3840000, bytes: 15360000]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/bias:0 (float32_ref 2400) [2400, bytes: 9600]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/kernel:0 (float32_ref 1200x2400) [2880000, bytes: 11520000]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/bias:0 (float32_ref 2400) [2400, bytes: 9600]\n",
      "dynamic_seq2seq/decoder/output_projection/kernel:0 (float32_ref 600x3819) [2291400, bytes: 9165600]\n",
      "dynamic_seq2seq/decoder/output_projection/bias:0 (float32_ref 3819) [3819, bytes: 15276]\n",
      "Total size of variables: 13799219\n",
      "Total bytes of variables: 55196876\n",
      "Restore graph from save_run/MT_S/run1\n",
      "INFO:tensorflow:Restoring parameters from save_run/MT_S/run1\n",
      "Graph restored!\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "infer_params = default_params\n",
    "infer_params['dataset'] = dataset_MT\n",
    "infer_params['lstm_size_enc'] = 600\n",
    "infer_params['lstm_size_dec'] = 600\n",
    "infer_params['nb_layers_enc'] = 2\n",
    "infer_params['nb_layers_dec'] = 2\n",
    "infer_params['embedding_dim'] = 400 # because GLoVe+charemb\n",
    "infer_params['init_emb'] = np.vstack(list(map(lambda i: dataset_MT.data.vocab_src.embeddings[dataset_MT.data.vocab_src.idx2lab[i]],\\\n",
    "                                              np.arange(dataset_MT.data.vocab_src.size)))).astype(np.float32)\n",
    "infer_params['batch_size'] = dataset_MT.data.get_length_set('val')\n",
    "infer_params['mode'] = 'INFER' \n",
    "infer_params['save_path'] = 'save_run/MT_L/run1'\n",
    "\n",
    "nmt_infer  =  NMT(infer_params)\n",
    "  \n",
    "nmt_infer.build_model()\n",
    "\n",
    "model_summary()\n",
    "\n",
    "idx = np.arange(dataset_MT.data.get_length_set('val')) # predict whole set at once\n",
    "preds = nmt_infer.infer(dataset_MT.data.data_tok['val'], idx, restore_path =  infer_params['save_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall BLEU-4 on 148 sentences: 0.0162\n",
      "------------------------------------------------------------\n",
      "Example n°1:\n",
      "\n",
      "Src sentence:  a man in a cluttered office is using the telephone\n",
      "Tgt sentence:  ein mann telefoniert in einem unaufgeräumten büro\n",
      "Tgt predicted: <s> ein ein mann in einem einem . . </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°2:\n",
      "\n",
      "Src sentence:  a female playing a song on her violin .\n",
      "Tgt sentence:  eine frau spielt ein lied auf ihrer geige .\n",
      "Tgt predicted: <s> ein ein mann in einem . . . </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°3:\n",
      "\n",
      "Src sentence:  a young woman is making rugs in the rain forest\n",
      "Tgt sentence:  eine junge frau fertigt im regenwald teppiche an\n",
      "Tgt predicted: <s> ein ein mann in einem einem . . </s> </s>\n",
      "Bleu score:    0\n",
      "------------------------------------------------------------\n",
      "Example n°4:\n",
      "\n",
      "Src sentence:  a cute baby is smiling at another child .\n",
      "Tgt sentence:  ein süßes baby lächelt einem anderen kind zu .\n",
      "Tgt predicted: <s> ein ein mann in einem . . . </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°5:\n",
      "\n",
      "Src sentence:  three men are walking on a road in the mountains .\n",
      "Tgt sentence:  drei männer gehen auf einer straße in den bergen .\n",
      "Tgt predicted: <s> ein ein mann in einem einem . . </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°6:\n",
      "\n",
      "Src sentence:  a young girl running by herself in a park .\n",
      "Tgt sentence:  ein junges mädchen läuft allein durch einen park .\n",
      "Tgt predicted: <s> ein ein mann in einem einem . . </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°7:\n",
      "\n",
      "Src sentence:  a woman sits at a dark bar .\n",
      "Tgt sentence:  eine frau sitzt an einer dunklen bar .\n",
      "Tgt predicted: <s> ein ein mann auf einem . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°8:\n",
      "\n",
      "Src sentence:  a man drives an old-fashioned red race car .\n",
      "Tgt sentence:  ein mann fährt ein altmodisches rotes rennauto .\n",
      "Tgt predicted: <s> ein ein mann auf einem einem . . </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°9:\n",
      "\n",
      "Src sentence:  three small dogs sniff at something .\n",
      "Tgt sentence:  drei kleine hunde schnüffeln an etwas .\n",
      "Tgt predicted: <s> ein ein in einem . . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°10:\n",
      "\n",
      "Src sentence:  two girls walking down the street .\n",
      "Tgt sentence:  zwei mädchen gehen eine straße entlang .\n",
      "Tgt predicted: <s> ein mann in einem . . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°11:\n",
      "\n",
      "Src sentence:  a man in a restaurant having lunch .\n",
      "Tgt sentence:  ein mann isst in einem restaurant zu mittag .\n",
      "Tgt predicted: <s> ein ein mann in einem . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°12:\n",
      "\n",
      "Src sentence:  three women smiling and sitting down .\n",
      "Tgt sentence:  drei frauen sitzen da und lächeln .\n",
      "Tgt predicted: <s> ein mann in einem . . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°13:\n",
      "\n",
      "Src sentence:  a man and woman fishing at the beach .\n",
      "Tgt sentence:  ein mann und eine frau fischen am strand .\n",
      "Tgt predicted: <s> ein ein mann auf einem . . . </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°14:\n",
      "\n",
      "Src sentence:  kids are riding a swinging carnival ride\n",
      "Tgt sentence:  kinder fahren in einem kettenkarussell\n",
      "Tgt predicted: <s> ein ein in einem . . </s> </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°15:\n",
      "\n",
      "Src sentence:  two men in the military are playing baseball .\n",
      "Tgt sentence:  zwei männer beim militär spielen baseball .\n",
      "Tgt predicted: <s> ein ein in auf einem . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "BLEU_set(dataset_MT, idx, preds, 'val', samples=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph of model is built.\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "src_embedding:0 (float32_ref 3023x400) [1209200, bytes: 4836800]\n",
      "tgt_embedding:0 (float32_ref 3819x400) [1527600, bytes: 6110400]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/kernel:0 (float32_ref 700x1200) [840000, bytes: 3360000]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/fw/lstm_cell/bias:0 (float32_ref 1200) [1200, bytes: 4800]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/kernel:0 (float32_ref 700x1200) [840000, bytes: 3360000]\n",
      "dynamic_seq2seq/encoder/bidirectional_rnn/bw/lstm_cell/bias:0 (float32_ref 1200) [1200, bytes: 4800]\n",
      "dynamic_seq2seq/decoder/memory_layer/kernel:0 (float32_ref 600x600) [360000, bytes: 1440000]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/kernel:0 (float32_ref 1600x2400) [3840000, bytes: 15360000]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_0/lstm_cell/bias:0 (float32_ref 2400) [2400, bytes: 9600]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/kernel:0 (float32_ref 1200x2400) [2880000, bytes: 11520000]\n",
      "dynamic_seq2seq/decoder/attention_wrapper/multi_rnn_cell/cell_1/lstm_cell/bias:0 (float32_ref 2400) [2400, bytes: 9600]\n",
      "dynamic_seq2seq/decoder/output_projection/kernel:0 (float32_ref 600x3819) [2291400, bytes: 9165600]\n",
      "dynamic_seq2seq/decoder/output_projection/bias:0 (float32_ref 3819) [3819, bytes: 15276]\n",
      "Total size of variables: 13799219\n",
      "Total bytes of variables: 55196876\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "infer_params = default_params\n",
    "infer_params['dataset'] = dataset_MT\n",
    "infer_params['lstm_size_enc'] = 600\n",
    "infer_params['lstm_size_dec'] = 600\n",
    "infer_params['nb_layers_enc'] = 2\n",
    "infer_params['nb_layers_dec'] = 2\n",
    "infer_params['embedding_dim'] = 400 # because GLoVe+charemb\n",
    "infer_params['init_emb'] = np.vstack(list(map(lambda i: dataset_MT.data.vocab_src.embeddings[dataset_MT.data.vocab_src.idx2lab[i]],\\\n",
    "                                              np.arange(dataset_MT.data.vocab_src.size)))).astype(np.float32)\n",
    "infer_params['batch_size'] = dataset_MT.data.get_length_set('test')\n",
    "infer_params['mode'] = 'INFER' \n",
    "infer_params['save_path'] = 'save_run/MT_L/run1'\n",
    "\n",
    "nmt_infer  =  NMT(infer_params)\n",
    "  \n",
    "nmt_infer.build_model()\n",
    "\n",
    "model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore graph from save_run/MT_S/run1\n",
      "INFO:tensorflow:Restoring parameters from save_run/MT_S/run1\n",
      "Graph restored!\n"
     ]
    }
   ],
   "source": [
    "idx = np.arange(dataset_MT.data.get_length_set('test')) # predict whole set at once\n",
    "preds = nmt_infer.infer(dataset_MT.data.data_tok['test'], idx, restore_path =  infer_params['save_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall BLEU-4 on 181 sentences: 0.0143\n",
      "------------------------------------------------------------\n",
      "Example n°1:\n",
      "\n",
      "Src sentence:  people are fixing the roof of a house .\n",
      "Tgt sentence:  leute reparieren das dach eines hauses .\n",
      "Tgt predicted: <s> ein mann in auf einem . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°2:\n",
      "\n",
      "Src sentence:  a group of people standing in front of an igloo .\n",
      "Tgt sentence:  eine gruppe von menschen steht vor einem iglu .\n",
      "Tgt predicted: <s> ein ein mann auf einem einem . . . </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°3:\n",
      "\n",
      "Src sentence:  a guy works on a building .\n",
      "Tgt sentence:  ein typ arbeitet an einem gebäude .\n",
      "Tgt predicted: <s> ein mann in einem einem . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°4:\n",
      "\n",
      "Src sentence:  three people sit in a cave .\n",
      "Tgt sentence:  drei leute sitzen in einer höhle .\n",
      "Tgt predicted: <s> ein mann in einem . . </s> </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°5:\n",
      "\n",
      "Src sentence:  people standing outside of a building .\n",
      "Tgt sentence:  leute , die vor einem gebäude stehen .\n",
      "Tgt predicted: <s> ein mann in einem . . </s> </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°6:\n",
      "\n",
      "Src sentence:  a man cutting branches of trees .\n",
      "Tgt sentence:  ein mann schneidet äste von bäumen .\n",
      "Tgt predicted: <s> ein mann in einem . . </s> </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°7:\n",
      "\n",
      "Src sentence:  a child is splashing in the water\n",
      "Tgt sentence:  ein kind planscht im wasser .\n",
      "Tgt predicted: <s> ein mann in einem . . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°8:\n",
      "\n",
      "Src sentence:  a pretty woman plays a harpsichord .\n",
      "Tgt sentence:  eine schöne frau spielt auf einer harfe .\n",
      "Tgt predicted: <s> ein mann in einem einem . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°9:\n",
      "\n",
      "Src sentence:  the young lady is looking at the pizza .\n",
      "Tgt sentence:  die junge dame sieht auf die pizza .\n",
      "Tgt predicted: <s> ein ein in auf einem . . . </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°10:\n",
      "\n",
      "Src sentence:  people sit inside a train .\n",
      "Tgt sentence:  leute sitzen in einem zug .\n",
      "Tgt predicted: <s> ein mann in einem . . </s> </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°11:\n",
      "\n",
      "Src sentence:  a toddler is cooking with another person .\n",
      "Tgt sentence:  ein kleines kind kocht mit einer anderen person .\n",
      "Tgt predicted: <s> ein ein mann einem einem . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°12:\n",
      "\n",
      "Src sentence:  a man cooking food on the stove .\n",
      "Tgt sentence:  ein mann bereitet am herd essen zu .\n",
      "Tgt predicted: <s> ein ein in auf einem . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°13:\n",
      "\n",
      "Src sentence:  a large group of people fill a street .\n",
      "Tgt sentence:  eine große menschenmenge füllt eine straße .\n",
      "Tgt predicted: <s> ein ein mann auf einem . . . </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°14:\n",
      "\n",
      "Src sentence:  a man on a tag line going into the water .\n",
      "Tgt sentence:  ein mann an einem halteseil geht ins wasser .\n",
      "Tgt predicted: <s> ein ein mann in einem einem . . . </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°15:\n",
      "\n",
      "Src sentence:  a car parked at the beach .\n",
      "Tgt sentence:  ein am strand geparktes auto .\n",
      "Tgt predicted: <s> ein mann in auf . . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "BLEU_set(dataset_MT, idx, preds, 'test', samples=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the decoder to get CoVe Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore graph from save_run/MT_S/run1\n",
      "INFO:tensorflow:Restoring parameters from save_run/MT_S/run1\n",
      "Graph restored!\n"
     ]
    }
   ],
   "source": [
    "idx = np.arange(dataset_MT.data.get_length_set('test')) # predict whole set at once\n",
    "preds = nmt_infer.infer(dataset_MT.data.data_tok['test'], idx, restore_path =  infer_params['save_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall BLEU-4 on 181 sentences: 0.0144\n",
      "------------------------------------------------------------\n",
      "Example n°1:\n",
      "\n",
      "Src sentence:  people are fixing the roof of a house .\n",
      "Tgt sentence:  leute reparieren das dach eines hauses .\n",
      "Tgt predicted: <s> ein mann in auf einem . . </s> </s> </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n",
      "Example n°2:\n",
      "\n",
      "Src sentence:  a group of people standing in front of an igloo .\n",
      "Tgt sentence:  eine gruppe von menschen steht vor einem iglu .\n",
      "Tgt predicted: <s> ein ein mann auf einem einem . . . </s>\n",
      "Bleu score:    0.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "BLEU_set(dataset_MT, idx, preds, 'test', samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore graph from save_run/MT_S/run1\n",
      "INFO:tensorflow:Restoring parameters from save_run/MT_S/run1\n",
      "Graph restored!\n"
     ]
    }
   ],
   "source": [
    "emb = nmt_infer.CoVe(dataset_MT.data.data_tok['test'], idx, restore_path=infer_params['save_path'], with_emb=True) # with_emb to add or not original embeddings (GloVe+char emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying the number of tokens is matching the non-zero embedding outputed by the model.\n",
    "Sentence 0 has 9 tokens while sentence 1 has 11 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181, 50, 1000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((emb[0]!=0).sum(axis=1)==1000).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((emb[1]!=0).sum(axis=1)==1000).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_1_8)",
   "language": "python",
   "name": "tf_1_8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
